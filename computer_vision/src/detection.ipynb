{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw, ImageEnhance\n",
    "import torch\n",
    "import numpy as np\n",
    "from facenet_pytorch import MTCNN, InceptionResnetV1\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FaceDetection():\n",
    "    \n",
    "    def __init__(self, mtcnn):\n",
    "        self.mtcnn = mtcnn\n",
    "    \n",
    "    def find(self, image):\n",
    "        return self.mtcnn.detect(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mtcnn = MTCNN(keep_all=True, min_face_size=10)\n",
    "detection = FaceDetection(mtcnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = Image.open(\"test_negative_false.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxes, probs = detection.find(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "boxes\n",
    "print(boxes)\n",
    "ss = sorted(boxes, key = lambda box: (box[1] - box[3]) * (box[0] - box[2]), reverse=True)\n",
    "for s in ss:\n",
    "    for x in s:\n",
    "        print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_image = np.uint8(image)\n",
    "np_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (100, 100))\n",
    "faces = []\n",
    "for i, box in enumerate(boxes):\n",
    "    plt.subplot(1, len(boxes), i+1)\n",
    "    face = np_image[int(box[1]): int(box[3]), int(box[0]): int(box[2])]\n",
    "    area = (box[1] - box[3]) * (box[0] - box[2])\n",
    "    print(f\"Area {area}\")\n",
    "    print(face.shape)\n",
    "    faces.append(face)\n",
    "    plt.imshow(face)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet = InceptionResnetV1(pretrained='vggface2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faces = mtcnn(image)\n",
    "print(faces.shape)\n",
    "print(faces[0].shape)\n",
    "print(faces[:2].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_face = faces[0]\n",
    "image_test = test_face.permute(1, 2, 0).numpy()\n",
    "image_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_vector = resnet(faces)\n",
    "face_vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_face1 = face_vector[0].detach().numpy()\n",
    "test_face2 = face_vector[1].detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "\n",
    "cos_sim = dot(test_face1, test_face1)/(norm(test_face1)*norm(test_face1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cos_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "import cv2\n",
    "from PIL import Image, ImageEnhance\n",
    "\n",
    "\n",
    "def cosine_simularity(a, b):\n",
    "    return dot(a, b) / (norm(a) * norm(b))\n",
    "\n",
    "def sharpen_image(image):\n",
    "    kernel = np.array([[-1,-1,-1], [-1,9,-1], [-1,-1,-1]])\n",
    "    if isinstance(image, torch.Tensor):\n",
    "        np_image = image.permute(1, 2, 0).numpy()\n",
    "        sharpened_image = cv2.filter2D(np_image, -1, kernel)\n",
    "        tensor_img = torch.from_numpy(sharpened_image)\n",
    "        return tensor_img.permute(2, 0, 1)\n",
    "    elif isinstance(image, np.ndarray):\n",
    "        sharpened_image = cv2.filter2D(image, -1, kernel)\n",
    "        return image\n",
    "\n",
    "class DocumentFaceChecker():\n",
    "\n",
    "    def __init__(self):\n",
    "        self.mtcnn = MTCNN(\n",
    "            keep_all=True, \n",
    "            min_face_size=30, \n",
    "            image_size = 200\n",
    "        )\n",
    "        self.embedding = InceptionResnetV1(pretrained='vggface2').eval()\n",
    "\n",
    "    def check(self, img_RGB):\n",
    "        boxes, probs = self.mtcnn.detect(img_RGB)\n",
    "        \n",
    "        if probs.shape[0] < 2:\n",
    "            raise Exception(\"couldn't find two faces\")\n",
    "            \n",
    "        sortedByArea = sorted(\n",
    "            boxes, \n",
    "            key = lambda box: (box[1] - box[3]) * (box[0] - box[2]), \n",
    "            reverse=True\n",
    "        )\n",
    "        faces = self.mtcnn.extract(img_RGB, sortedByArea, None)\n",
    "        print(faces[1].shape)\n",
    "        sharpened_image = sharpen_image(faces[1])\n",
    "        print(sharpened_image.shape)\n",
    "        faces[1] = sharpened_image\n",
    "        plt.figure()\n",
    "        plt.imshow(faces[1].permute(1, 2, 0).numpy())\n",
    "        plt.figure()\n",
    "        plt.imshow(faces[0].permute(1, 2, 0).numpy())\n",
    "        \n",
    "        print(faces.shape)\n",
    "#         plt.figure()\n",
    "#         np_image = np.uint8(img_RGB)\n",
    "#         for i, box in enumerate(sortedByArea):\n",
    "#             plt.subplot(1, len(sortedByArea), i+1)\n",
    "#             face = np_image[int(box[1]): int(box[3]), int(box[0]): int(box[2])]\n",
    "#             plt.imshow(face)\n",
    "        vector_faces = self.embedding(faces)[:2]\n",
    "        face1, face2 = vector_faces[0].detach(), vector_faces[1].detach()\n",
    "        return cosine_simularity(face1, face2)\n",
    "\n",
    "image = Image.open(\"positive_true_2.jpg\")\n",
    "np_image = np.uint8(image)\n",
    "print(np_image.shape)\n",
    "doc_check = DocumentFaceChecker()\n",
    "print(doc_check.check(image))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "face-utils",
   "language": "python",
   "name": "face-utils"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
